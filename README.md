# KnowledgeBase_Manager

Plataforma completa para gestionar Vector Stores con OpenAI. Incluye interfaz web moderna (TypeScript + React) y API REST (Python + FastAPI) para subir documentos, crear bases de conocimiento y hacer consultas con RAG.

## ğŸš€ Inicio RÃ¡pido

### OpciÃ³n 1: Plataforma Web Completa (Recomendado)

```bash

# 1. Instala el mÃ³dulo venv 
apt install python3-venv

# 2. Crea el entorno virtual
python3 -m venv venv

# 3. Activa el entorno virtual
source venv/bin/activate

# 4. Instalar dependencias Python
pip install -r requirements.txt

# 5. En otra terminal, instalar dependencias del frontend
cd frontend
npm install
cd ..

# 6. Iniciar toda la plataforma (backend + frontend)
./start_platform.sh
```

Abre http://localhost:3000 en tu navegador.

### OpciÃ³n 2: Solo Backend API

```bash
# Iniciar solo el backend
./start_backend.sh
```

API disponible en http://localhost:8000

### OpciÃ³n 3: CLI (LÃ­nea de Comandos)

```bash
# 1. Configurar API key
export OPENAI_API_KEY="sk-proj-..."

# 2. Setup completo
python main.py --action setup --pattern "docs/*.md"

# 3. Modo interactivo
python main.py --action interactive
```

## ğŸ“ Estructura del Proyecto

```
KnowledgeBase_Manager/
â”œâ”€â”€ Backend (Python + FastAPI)
â”‚   â”œâ”€â”€ api.py                      # API REST principal
â”‚   â”œâ”€â”€ config.py                   # ConfiguraciÃ³n OpenAI
â”‚   â”œâ”€â”€ vector_store_manager.py     # GestiÃ³n de Vector Stores
â”‚   â”œâ”€â”€ file_uploader.py            # Subida de archivos
â”‚   â”œâ”€â”€ batch_manager.py            # GestiÃ³n de batches
â”‚   â”œâ”€â”€ vector_search.py            # BÃºsqueda vectorial
â”‚   â”œâ”€â”€ rag_assistant.py            # Asistente RAG
â”‚   â”œâ”€â”€ main.py                     # CLI
â”‚   â””â”€â”€ requirements.txt            # Dependencias Python
â”‚
â”œâ”€â”€ Frontend (TypeScript + React + Vite)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ConfigPanel.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUploader.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ VectorStoreManager.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ChatInterface.tsx
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ Scripts de Inicio
â”‚   â”œâ”€â”€ start_platform.sh           # Inicia backend + frontend
â”‚   â”œâ”€â”€ start_backend.sh            # Solo backend
â”‚   â””â”€â”€ start_frontend.sh           # Solo frontend
â”‚
â””â”€â”€ DocumentaciÃ³n
    â”œâ”€â”€ README.md                   # Este archivo
    â””â”€â”€ PLATFORM_README.md          # DocumentaciÃ³n detallada
```

## âš™ï¸ Diagramass de Flujo de Trabajo

### 1. Arquitectura General de la API
```mermaid

flowchart TB
    subgraph Cliente["ğŸ–¥ï¸ Cliente (Frontend)"]
        UI[Interfaz Web]
    end

    subgraph API["âš¡ FastAPI Backend"]
        direction TB
        CORS[CORS Middleware]
        
        subgraph Endpoints["Endpoints"]
            CONFIG["/api/config"]
            UPLOAD["/api/upload"]
            FILES["/api/files"]
            VS["/api/vector-store"]
            QUERY["/api/query"]
        end
        
        subgraph State["AppState"]
            CLIENT[OpenAI Client]
            APIKEY[API Key]
            VSID[Vector Store ID]
            UPLOADED[Uploaded Files]
        end
    end

    subgraph OpenAI["â˜ï¸ OpenAI API"]
        OFILES[Files API]
        OVS[Vector Stores API]
        OCHAT[Chat Completions]
    end

    UI --> CORS
    CORS --> Endpoints
    Endpoints --> State
    State --> OpenAI
```

### 2. Mapa de Endpoints
```mermaid

flowchart LR
    subgraph Config["âš™ï¸ ConfiguraciÃ³n"]
        C1["POST /api/config"]
    end

    subgraph Files["ğŸ“ Archivos"]
        F1["POST /api/upload"]
        F2["GET /api/files"]
    end

    subgraph VectorStores["ğŸ—„ï¸ Vector Stores"]
        VS1["POST /api/vector-store"]
        VS2["GET /api/vector-stores"]
        VS3["GET /api/status/{id}"]
        VS4["GET /{id}/files"]
        VS5["POST /{id}/add-files"]
        VS6["DELETE /{id}/files/{fid}"]
        VS7["GET /{id}/files/{fid}/content"]
        VS8["GET /{id}/batch/{bid}/status"]
    end

    subgraph Query["ğŸ” Consultas RAG"]
        Q1["POST /api/query"]
    end

    subgraph Health["ğŸ’š Salud"]
        H1["GET /"]
        H2["GET /health"]
    end

    C1 --> Files
    Files --> VectorStores
    VectorStores --> Query
```

### 3. Flujo de Trabajo Principal
```mermaid

sequenceDiagram
    autonumber
    participant U as ğŸ‘¤ Usuario
    participant API as âš¡ API
    participant OAI as â˜ï¸ OpenAI

    rect rgb(240, 248, 255)
        Note over U,OAI: 1ï¸âƒ£ ConfiguraciÃ³n
        U->>API: POST /api/config {api_key}
        API->>OAI: Validar API Key
        OAI-->>API: âœ“ VÃ¡lida
        API-->>U: {success: true}
    end

    rect rgb(255, 248, 240)
        Note over U,OAI: 2ï¸âƒ£ Subida de Archivos
        U->>API: POST /api/upload (PDF/MD/TXT)
        API->>OAI: files.create()
        OAI-->>API: file_id
        API-->>U: {file_id, filename, size}
    end

    rect rgb(240, 255, 240)
        Note over U,OAI: 3ï¸âƒ£ Crear Vector Store
        U->>API: POST /api/vector-store {name}
        API->>OAI: vector_stores.create()
        API->>OAI: file_batches.create(file_ids)
        OAI-->>API: vector_store_id
        API-->>U: {vector_store_id}
    end

    rect rgb(255, 240, 255)
        Note over U,OAI: 4ï¸âƒ£ Consulta RAG
        U->>API: POST /api/query {query}
        API->>OAI: Vector Store Search
        OAI-->>API: Chunks relevantes
        API->>OAI: chat.completions.create()
        OAI-->>API: Respuesta generada
        API-->>U: {answer, sources, context}
    end
```

### 4. Flujo de Consulta RAG Detallado
```mermaid

flowchart TD
    A[ğŸ“ Query del Usuario] --> B{Â¿API Key configurada?}
    B -->|No| C[âŒ Error 400]
    B -->|SÃ­| D{Â¿Vector Store existe?}
    D -->|No| E[âŒ Error 400]
    D -->|SÃ­| F[ğŸ” BÃºsqueda en Vector Store]
    
    F --> G[Obtener Top 10 Chunks]
    G --> H{Â¿Hay contexto?}
    
    H -->|No| I[ğŸ“­ Sin informaciÃ³n relevante]
    H -->|SÃ­| J[ğŸ“¦ Construir Contexto]
    
    J --> K[ğŸ§  System Prompt + Contexto]
    K --> L[ğŸ¤– Chat Completion]
    L --> M[âœ… Respuesta con Sources]
    
    I --> N[Retornar QueryResponse]
    M --> N
```

### 5. Estados del Vector Store

```mermaid
stateDiagram-v2
    [*] --> SinConfigurar: Inicio
    
    SinConfigurar --> Configurado: POST /api/config
    
    Configurado --> ArchivosSubidos: POST /api/upload
    
    ArchivosSubidos --> ArchivosSubidos: MÃ¡s uploads
    
    ArchivosSubidos --> Indexando: POST /api/vector-store
    
    Indexando --> Listo: Batch completado
    Indexando --> Error: Fallo en indexaciÃ³n
    
    Listo --> Consultando: POST /api/query
    Consultando --> Listo: Respuesta generada
    
    Listo --> Indexando: POST /{id}/add-files
    
    Error --> ArchivosSubidos: Reintentar
```

### 6. Modelos de Datos
```mermaid

classDiagram
    class ConfigRequest {
        +str api_key
    }
    
    class ConfigResponse {
        +bool success
        +str message
    }
    
    class VectorStoreRequest {
        +str name
    }
    
    class VectorStoreResponse {
        +bool success
        +str vector_store_id
        +str message
    }
    
    class QueryRequest {
        +str query
        +str vector_store_id?
        +str model
    }
    
    class QueryResponse {
        +bool success
        +str answer
        +List~str~ sources
        +str context
    }
    
    class FileInfo {
        +str file_id
        +str filename
        +int size
        +str uploaded_at
    }
    
    class StatusResponse {
        +str vector_store_id?
        +str vector_store_name?
        +int file_count
        +str status
    }
    
    class AppState {
        +OpenAI client
        +str api_key
        +str vector_store_id
        +List~Dict~ uploaded_files
    }

    ConfigRequest --> ConfigResponse : genera
    VectorStoreRequest --> VectorStoreResponse : genera
    QueryRequest --> QueryResponse : genera
```

### 7. GestiÃ³n de Archivos en Vector Store
```mermaid

flowchart TD
    subgraph Upload["ğŸ“¤ Subida"]
        A[Usuario sube archivo] --> B{ExtensiÃ³n vÃ¡lida?}
        B -->|.pdf .md .txt| C[Subir a OpenAI Files API]
        B -->|Otra| D[âŒ Error 400]
        C --> E[Guardar en state.uploaded_files]
    end

    subgraph Index["ğŸ“‡ IndexaciÃ³n"]
        E --> F[Crear Vector Store]
        F --> G[Crear File Batch]
        G --> H[IndexaciÃ³n en progreso]
        H --> I{Batch status?}
        I -->|completed| J[âœ… Listo para consultas]
        I -->|in_progress| H
        I -->|failed| K[âŒ Revisar errores]
    end

    subgraph Manage["ğŸ”§ GestiÃ³n"]
        J --> L[Listar archivos]
        J --> M[Agregar mÃ¡s archivos]
        J --> N[Eliminar archivos]
        J --> O[Ver contenido]
    end
```

### 8. Arquitectura de Componentes
```mermaid

flowchart TB
    subgraph Frontend["ğŸ–¥ï¸ Frontend"]
        WEB[AplicaciÃ³n Web]
    end

    subgraph Backend["âš¡ FastAPI Backend"]
        direction TB
        
        subgraph Middleware
            CORS[CORS]
            LOG[Logging]
        end
        
        subgraph Controllers["Controladores"]
            CFG[Config Controller]
            FILE[File Controller]
            VS[VectorStore Controller]
            QRY[Query Controller]
        end
        
        subgraph Models["Modelos Pydantic"]
            REQ[Request Models]
            RES[Response Models]
        end
        
        subgraph State["Estado Global"]
            APP[AppState]
        end
    end

    subgraph External["â˜ï¸ Servicios Externos"]
        OPENAI[OpenAI API]
    end

    WEB <-->|HTTP/REST| Middleware
    Middleware --> Controllers
    Controllers --> Models
    Controllers --> State
    State <-->|SDK| OPENAI
```

## ğŸ¯ CaracterÃ­sticas

### Plataforma Web
- âœ… Interfaz moderna y responsive
- âœ… ConfiguraciÃ³n de OpenAI API Key
- âœ… Carga de archivos drag & drop (PDF, MD, TXT)
- âœ… CreaciÃ³n automÃ¡tica de Vector Stores
- âœ… Chat interactivo con RAG
- âœ… VisualizaciÃ³n de fuentes consultadas

### API REST
- âœ… Endpoints completos para gestiÃ³n
- âœ… Subida de archivos multipart
- âœ… CreaciÃ³n de Vector Stores
- âœ… BÃºsqueda vectorial
- âœ… Consultas RAG con GPT-5+
- âœ… CORS configurado

### CLI
- âœ… Setup automatizado
- âœ… Modo interactivo
- âœ… Tests de validaciÃ³n
- âœ… BÃºsqueda y consultas

## âš™ï¸ DocumentaciÃ³n Completa

Ver [PLATFORM_README.md](PLATFORM_README.md) para:
- GuÃ­a de instalaciÃ³n detallada
- DocumentaciÃ³n de API endpoints
- Ejemplos de uso
- SoluciÃ³n de problemas
- Arquitectura del sistema

## ğŸ› ï¸ Requisitos

- Python 3.8+
- Node.js 16+
- OpenAI API Key (con acceso a GPT-5 o superior)

## ğŸ“– Uso de la Plataforma Web

1. **Configurar API Key**: Ingresa tu OpenAI API key
2. **Subir Archivos**: Arrastra o selecciona archivos PDF/MD/TXT
3. **Crear Vector Store**: Dale un nombre a tu base de conocimiento
4. **Hacer Consultas**: Pregunta sobre el contenido de tus documentos

## ğŸ’¡ Ejemplos de Consultas

- "Â¿CuÃ¡l es la polÃ­tica de devoluciones?"
- "Â¿CuÃ¡nto cuesta el envÃ­o?"
- "Â¿QuÃ© productos tienen garantÃ­a extendida?"
- "Resume las caracterÃ­sticas principales"

## ğŸ”§ Desarrollo

### Backend
```bash
# Instalar dependencias
pip install -r requirements.txt

# Iniciar con hot-reload
uvicorn api:app --reload --port 8000
```

### Frontend
```bash
cd frontend

# Instalar dependencias
npm install

# Iniciar con hot-reload
npm run dev
```

## ğŸ“ Licencia

CÃ³digo abierto - Uso libre

---

**Desarrollado con OpenAI API + FastAPI + React + TypeScript**
