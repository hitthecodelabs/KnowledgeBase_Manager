#!/usr/bin/env python3
"""
vector_search.py - B√∫squeda Sem√°ntica en Vector Stores
=======================================================

Este m√≥dulo proporciona funcionalidades para realizar b√∫squedas
sem√°nticas en Vector Stores de OpenAI.

¬øC√≥mo funciona la b√∫squeda?
---------------------------
1. Env√≠as una query (pregunta o texto)
2. OpenAI genera un embedding de la query
3. Busca los chunks m√°s similares en el vector store
4. Retorna los K resultados m√°s relevantes con scores

Estructura del resultado:
    {
        "data": [
            {
                "file_id": "file-abc123",
                "filename": "faq.md",
                "score": 0.87,
                "content": [
                    {"type": "text", "text": "...contenido del chunk..."}
                ]
            },
            ...
        ]
    }

Ejemplo de uso:
---------------
    from vector_search import search_vector_store, extract_context
    
    # Buscar
    hits = search_vector_store("vs_123...", "¬øCu√°l es la pol√≠tica de devoluci√≥n?")
    
    # Extraer contexto
    context = extract_context(hits, max_chars=4000)

Autor: [Tu nombre]
Fecha: 2025
"""

import httpx
from typing import List, Dict, Any, Optional, Tuple

from config import client, OPENAI_API_KEY, DEFAULT_SEARCH_RESULTS, MAX_CONTEXT_CHARS


# =============================================================================
# B√öSQUEDA EN VECTOR STORE
# =============================================================================

def search_vector_store(
    vector_store_id: str,
    query: str,
    max_results: int = DEFAULT_SEARCH_RESULTS,
    score_threshold: Optional[float] = None
) -> Dict[str, Any]:
    """
    Realiza una b√∫squeda sem√°ntica en un Vector Store.
    
    Env√≠a la query al endpoint de b√∫squeda de OpenAI, que genera
    embeddings y encuentra los chunks m√°s similares sem√°nticamente.
    
    Args:
        vector_store_id: ID del vector store a buscar.
                        Formato: vs_XXXXXXXXXXXX
        
        query: Texto de b√∫squeda (pregunta o consulta).
              Ejemplos:
              - "What is the return policy?"
              - "How much does shipping cost?"
              - "¬øCu√°les son los materiales sostenibles?"
        
        max_results: N√∫mero m√°ximo de resultados (default: 5).
                    M√°s resultados = m√°s contexto pero m√°s tokens.
        
        score_threshold: Filtrar resultados por score m√≠nimo.
                        Rango: 0.0 a 1.0 (mayor = m√°s relevante)
                        None = sin filtro
    
    Returns:
        Dict con estructura:
        {
            "data": [
                {
                    "file_id": str,      # ID del archivo fuente
                    "filename": str,      # Nombre del archivo
                    "score": float,       # Relevancia (0-1)
                    "content": [          # Chunks de texto
                        {"type": "text", "text": str}
                    ],
                    "attributes": dict    # Metadatos adicionales
                },
                ...
            ],
            "has_more": bool,
            "next_page": str | None
        }
    
    Ejemplo:
        >>> hits = search_vector_store(
        ...     "vs_6932899d...",
        ...     "Do I have to pay customs or fees?",
        ...     max_results=5
        ... )
        üîç Buscando: "Do I have to pay customs or fees?"
        ‚úì Encontrados 5 resultados
        
        >>> for h in hits["data"]:
        ...     print(f"{h['score']:.2f} - {h['filename']}")
        0.89 - faq_shipping_delivery.md
        0.82 - faq_payment.md
        0.76 - faq_order.md
    
    Notas:
        - Esta funci√≥n usa httpx directamente (API endpoint)
        - El header OpenAI-Beta es necesario para Assistants v2
        - Los scores son normalizados entre 0 y 1
    """
    print(f'üîç Buscando: "{query[:50]}..."' if len(query) > 50 else f'üîç Buscando: "{query}"')
    
    # Construir URL y headers
    url = f"https://api.openai.com/v1/vector_stores/{vector_store_id}/search"
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
        "OpenAI-Beta": "assistants=v2"
    }
    
    # Payload de b√∫squeda
    payload = {
        "query": query,
        "max_num_results": max_results
    }
    
    # Realizar b√∫squeda
    response = httpx.post(url, headers=headers, json=payload, timeout=30)
    response.raise_for_status()
    
    results = response.json()
    
    # Filtrar por threshold si se especific√≥
    if score_threshold and "data" in results:
        results["data"] = [
            h for h in results["data"]
            if h.get("score", 0) >= score_threshold
        ]
    
    num_results = len(results.get("data", []))
    print(f"‚úì Encontrados {num_results} resultados")
    
    return results


# =============================================================================
# EXTRAER TEXTO DE RESULTADOS
# =============================================================================

def extract_text_from_hit(hit: Dict[str, Any]) -> str:
    """
    Extrae el texto de un √∫nico resultado de b√∫squeda.
    
    Los resultados tienen una estructura de "content" que puede
    contener m√∫ltiples partes de texto. Esta funci√≥n las combina.
    
    Args:
        hit: Un elemento de la lista "data" del resultado de b√∫squeda
    
    Returns:
        str: Texto combinado del chunk
    
    Ejemplo:
        >>> hit = {
        ...     "content": [
        ...         {"type": "text", "text": "P√°rrafo 1..."},
        ...         {"type": "text", "text": "P√°rrafo 2..."}
        ...     ]
        ... }
        >>> text = extract_text_from_hit(hit)
        >>> print(text)
        P√°rrafo 1...
        P√°rrafo 2...
    """
    parts = hit.get("content", [])
    texts = []
    
    for part in parts:
        if isinstance(part, dict):
            # Intentar obtener texto de diferentes formatos
            if "text" in part:
                texts.append(part["text"])
            elif part.get("type") == "text" and "text" in part:
                texts.append(part["text"])
    
    return "\n".join(texts).strip()


# =============================================================================
# EXTRAER CONTEXTO FORMATEADO
# =============================================================================

def extract_context(
    search_results: Dict[str, Any],
    max_chars: int = MAX_CONTEXT_CHARS,
    include_source: bool = True,
    separator: str = "\n\n---\n\n"
) -> str:
    """
    Extrae y formatea el contexto de los resultados de b√∫squeda.
    
    Combina todos los chunks encontrados en un string formateado
    listo para usar como contexto en un prompt de LLM.
    
    Args:
        search_results: Resultado de search_vector_store()
        max_chars: L√≠mite de caracteres (protecci√≥n de tokens)
        include_source: Si True, incluye referencia a archivo fuente
        separator: Separador entre chunks
    
    Returns:
        str: Contexto formateado y truncado
    
    Ejemplo:
        >>> hits = search_vector_store(vs_id, "return policy")
        >>> context = extract_context(hits, max_chars=4000)
        >>> print(context)
        [KB#1 - faq_returns.md]
        You can return items within 14 days...
        
        ---
        
        [KB#2 - policy_summary.md]
        Our return policy allows...
    """
    snippets: List[str] = []
    
    for i, hit in enumerate(search_results.get("data", []), start=1):
        text = extract_text_from_hit(hit)
        
        if not text:
            continue
        
        if include_source:
            filename = hit.get("filename", "unknown")
            score = hit.get("score", 0)
            header = f"[KB#{i} - {filename} (score: {score:.2f})]"
            snippets.append(f"{header}\n{text}")
        else:
            snippets.append(f"[KB#{i}]\n{text}")
    
    # Combinar y truncar
    context = separator.join(snippets)
    
    if len(context) > max_chars:
        context = context[:max_chars] + "\n\n[... truncado por l√≠mite de tokens ...]"
    
    return context


# =============================================================================
# B√öSQUEDA CON SNIPPETS (funci√≥n de conveniencia)
# =============================================================================

def search_and_extract(
    vector_store_id: str,
    query: str,
    max_results: int = 5,
    max_chars: int = MAX_CONTEXT_CHARS
) -> Tuple[str, Dict[str, Any]]:
    """
    Funci√≥n de conveniencia que busca y extrae contexto en un solo paso.
    
    Args:
        vector_store_id: ID del vector store
        query: Consulta de b√∫squeda
        max_results: N√∫mero m√°ximo de resultados
        max_chars: L√≠mite de caracteres del contexto
    
    Returns:
        Tuple[str, Dict]: (contexto_formateado, resultados_raw)
    
    Ejemplo:
        >>> context, raw_hits = search_and_extract(
        ...     "vs_123...",
        ...     "What is the shipping cost?",
        ...     max_results=3
        ... )
        >>> print(context[:200])
        [KB#1 - faq_shipping.md (score: 0.91)]
        Shipping costs ¬£6.99 for orders under ¬£112...
    """
    hits = search_vector_store(vector_store_id, query, max_results)
    context = extract_context(hits, max_chars)
    return context, hits


# =============================================================================
# MOSTRAR RESULTADOS (debug/exploraci√≥n)
# =============================================================================

def display_results(search_results: Dict[str, Any]) -> None:
    """
    Muestra los resultados de b√∫squeda de forma legible.
    
    √ötil para debugging y exploraci√≥n de qu√© est√° encontrando
    la b√∫squeda sem√°ntica.
    
    Args:
        search_results: Resultado de search_vector_store()
    
    Ejemplo:
        >>> hits = search_vector_store(vs_id, "shipping")
        >>> display_results(hits)
        
        ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        Resultado #1 (Score: 0.91)
        Archivo: faq_shipping_delivery.md
        ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        We offer free shipping on orders over ¬£112. For orders
        under ¬£112, shipping costs ¬£6.99...
        ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    """
    data = search_results.get("data", [])
    
    if not data:
        print("No se encontraron resultados")
        return
    
    for i, hit in enumerate(data, start=1):
        score = hit.get("score", 0)
        filename = hit.get("filename", "unknown")
        text = extract_text_from_hit(hit)
        
        print("\n" + "‚ïê" * 60)
        print(f"Resultado #{i} (Score: {score:.3f})")
        print(f"Archivo: {filename}")
        print("‚îÄ" * 60)
        
        # Truncar texto muy largo para display
        if len(text) > 500:
            print(text[:500] + "...")
        else:
            print(text)
    
    print("‚ïê" * 60)


# =============================================================================
# EJECUCI√ìN DIRECTA (demostraci√≥n)
# =============================================================================

if __name__ == "__main__":
    print("=" * 70)
    print("Demo: Vector Search")
    print("=" * 70)
    
    # Para demo real, configura tu VS_ID
    DEMO_VS_ID = "vs_6932899d0eb481919e4ccdb6ac7487"  # Reemplaza con tu ID
    
    demo_queries = [
        "Do I have to pay customs or fees?",
        "What is the return period?",
        "How much is shipping under ¬£112?"
    ]
    
    print(f"""
Para usar este m√≥dulo:

    from vector_search import search_and_extract, display_results
    
    # B√∫squeda simple
    context, hits = search_and_extract(
        vector_store_id="{DEMO_VS_ID}",
        query="What is your return policy?"
    )
    
    # Ver resultados
    display_results(hits)
    
    # Usar contexto en un prompt
    print(context)
""")
    
    # Intentar demo real si el VS existe
    try:
        print("\nüß™ Probando b√∫squeda de ejemplo...")
        context, hits = search_and_extract(
            DEMO_VS_ID,
            "Do I have to pay customs or fees?",
            max_results=3
        )
        display_results(hits)
    except Exception as e:
        print(f"‚ö† Demo no disponible: {e}")
        print("  (Configura un VS_ID v√°lido para probar)")
    
    print("\n" + "=" * 70)
